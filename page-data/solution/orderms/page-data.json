{"componentChunkName":"component---src-pages-solution-orderms-index-mdx","path":"/solution/orderms/","result":{"pageContext":{"frontmatter":{"title":"Vaccine Order Management","description":"This microservice manage order for vaccine"},"relativePagePath":"/solution/orderms/index.mdx","titleType":"append","MdxNode":{"id":"82a63082-b6f3-5eb8-b43f-4a09d60e13ea","children":[],"parent":"0263f179-df6c-5b1d-929c-92575467fd23","internal":{"content":"---\ntitle: Vaccine Order Management\ndescription: This microservice manage order for vaccine\n---\n<PageDescription>\nThis microservice manages vaccine order for a world wide demand and distribution.\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Build with s2i</AnchorLink>\n  <AnchorLink>Run Locally</AnchorLink>\n  <AnchorLink>Deploy to OpenShift</AnchorLink>\n  <AnchorLink>Usage Details</AnchorLink>\n</AnchorLinks>\n\n## Overview\n\nThis project implements a very simple event driven microservice to support the Create, Read, Update, of vaccine orders. This implementation highlights the following capbilities / patterns:\n\n* Quarkus reactive microservice using Microprofile 3.x - reactive messaging extension \n* DB2 with Hibernate ORM with Quarkus Panache\n* Quarkus Debezium Outbox pattern to get OrderEvents table and change data capture with Debezium.\n\nIn term of business scenario, a sale representative uses his mobile device to enter information about a vaccine order to be shipped to a given countries or a province within a country. \n\n ![](./images/order-ui.png)\n\nThe user interface is for demonstration purpose but illustrate some standard Vuejs development practices. \n\n ![](./images/vaccine-order-1.png)\n\n\nThe component writes to the database (DB2) all the orders received, but also produce records to Kafka via the Outbox pattern and change data capture.\n\n**Github repository:** [Vaccine-order-mgr](https://github.com/ibm-cloud-architecture/vaccine-order-mgr)\n\n**Order Life Cycle**\n\nThe order follows a set of states as described in the following diagram:\n\n ![](./images/vaccine-order-2.png)\n\n**Kafka topics produced to:**\n\n\n**Events produced:**\n\nWe will simplify the process and aggregate in the following event types:\n\n* orderCreated\n* orderUpdated\n\nSome events are related to the vaccine lot\n\n* lotAssignedToOrder\n* lotLoaded\n* lotDelivered\n\n## Build with s2i\n\nThis microservice is built using maven and Quarkus extensions. We have already pushed the last version of this service on dockerhub, if you do not want to build it. \n\nTo build and run locally see the [repository main readme]() as we have different docker-compose file to run in demonstration mode or in development mode to add more features to existing code base.\n\nIn this section we address how to use OpenShift Source to Image to build and deploy the application to OpenShift. The application is using environment variables to access to user, password, URLs to access DB2, and Kafka. So first thing is to define such secrets.\n\nAs an example we use a OpenShift project called vaccine_solution created with a command like `oc new-project vaccine_solution`.\n\n### Pre requisites\n\nThe orders are persisted in an external DB2 instance running on IBM Cloud Pack for Data. You need to get the username and password to connect to the DB2 instance with the jdbc URL (something like jdbc:db2://dashdb-....:50001/BLUDB)\n\nGet an instance of Kafka deployed on OpenShift (Strimzi, [Event Streams](https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/overview/pre-requisites#install-event-streams-using-operators)...). For Event Streams get URL of the bootstrap server and the service credentials (TLS certificates) following [those instructions.](https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/overview/pre-requisites#getting-tls-authentication-from-event-streams-on-openshift)\n\n### Defining secrets\n\nWe need to get IBM DB2 on Cloud credentials as secrets. So from the DB2 service credentials get the following attributes: user, password, and JDBC URL. You need to encrypt each of those values:\n\n```shell\n# Example of URL encryption\necho \"jdbc:db2://dashdb-txn-sbox-....services.dal.bluemix.net:50001/BLUDB:sslConnection=true;\" | base64\n```\n\nThen define a secret manifest with a command like:\n\n```shell\noc apply -f - <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: vaccine-order-db-secret\ndata:\n    db.url: ...encrypted URL...\n    db.user: ...encrypted user..\n    db.password: ...encrypted pwd\nEOF\n```\n\n\n```shell\n# if not logged yes to your openshift cluster where the docker private registry resides do:\noc login --token=... --server=https://c...\n\n# Then build the code using source 2 image and push the image to the internal registry\nmvn package -Dui.deps -Dui.dev -Dquarkus.kubernetes.deploy=true -DskipTests\n```\n\nIt can take some seconds to build and deploy: oc get pods -w lets you see the build pods and the running app once the build is done. As we expose the application an OpenShift route was created. The url is visible at the end of the build output, something like:\n\n...The deployed application can be accessed at: http://quarkus-kstreams-lab3...\n\n## Run\n\n\n### Deployment Parameters\n\nThe following deployment parameters are defined in the `app-deploy.yaml` file:\n\n| Name                                     | Required | Description                                                                                                            |\n|------------------------------------------|----------|------------------------------------------------------------------------------------------------------------------------|\n| KAFKA_BROKERS                            | YES      | Comma-separated list of Kafka brokers to connect to                                                                    |\n| KAFKA_APIKEY                             | NO       | API Key used to connect to SASL-secured Kafka brokers. This is required when connecting to IBM Event Streams clusters. |\n| TRUSTSTORE_ENABLED                       | NO       | Required to be set to `true` when connecting to IBM Event Streams on the IBM Cloud Pak for Integration (CP4I).         |\n| TRUSTSTORE_PATH                          | NO       | The local path to the required truststore file when connecting to IBM Event Streams on CP4I. See [**Volume Mounts**](#volume-mounts) below.  |\n| TRUSTSTORE_PWD                           | NO       | The password for the truststore file used for IBM Event Streams server verification. |\n| DBUSER | YES | Database user |\n| DBPWD | YES | Database user password |\n| SSLJDBCURL | YES | JDBC URL to connect to the database | \n\nYou can define a `.env` script to export the environment variables. \n\n### Run Locally\n\nWhen running the microservice locally you must specify all the required [deployment parameters](#deployment-parameters) environment variables. When using `appsody run` use the `--docker-options` flag being passed in from the Appsody CLI command. \nTwo options to start locally, one with quarkus, the other one with appsody\n\n**With Quarkus:**\n\n```shell\nsource ./scripts/setenv.sh\n./mvnw quarkus:dev\n```\n\n**With Appsody:** \n\n```shell\nsource ./scripts/setenv.sh\n\nappsody run --docker-options \"-e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY -e DBPWD=$DBPWD -e DBUSER=$DBUSER -e SSLJDBCURL=$SSLJDBCURL  -v $(pwd)/certs/es-cert.jks:/deployments/certs/es-cert.jks\"\n```\n\nFor more details on running the microservice locally, consult the Appsody run documentation as well as the deployment information contained in the app-deploy.yaml file.\n\n### Volume mounts\n\nThe order manager microservice requires up to one file to be injected at runtime for proper operation. As noted in the `TRUSTSTORE_PATH` parameter above, these files are SSL-based certificates which are required to verify the identity of the external service when calling it. These files are provided as `--docker-options \"-v host-src:container-dest ...\"` when running the microservice locally and as a Volume Mount when running the microservice on a Kubernetes cluster.\n\nThe `TRUSTSTORE_PATH` parameter is documented in the **Event Streams Certificates** section of the [Prerequisites](/microservices/prereqs/#ibm-event-streams-on-redhat-openshift-container-platform) page. The Appsody run command should include a parameter similar to `-v ./certs/es-cert.jks:/config/resources/security/es-cert.jks` in its `--docker-options` string to run this microservice locally.\n\n**Example:** `appsody run --docker-options \"-v /Users/myuser/Downloads/es-cert.jks:/config/resources/security/es-ssl/es-cert.jks\" ...`\n\n## Deploy to Openshift \n\n* Define a config map for the kafka brokers URL coming from the Event streams cluster connection panel:\n\n ![3](./images/es-cluster-connect.png)\n\n  ```shell\n  oc create configmap kafka-brokers --from-literal=brokers='es-cp4i-ibm-es-proxy-route-bootstrap-eventstreams-cp4i.gse-eda-demo-202005-fa9ee67c9ab6a7791435450358e564cc-0000.us-south.containers.appdomain.cloud:443' -n vaccine-cold-chain\n\n  ```\n\n* Define a secret for the event streams API key\n\n  ```shell\n  oc create secret generic es-cp4i-apikey --from-literal=binding='b77......tgMJZ' -n vaccine_solution\n  ```\n\n* Add a secret for the java truststore, downloaded from Event Stream console or using the CLI `cloudctl es certificates --format jks`\n\n  ```shell\n  oc create secret generic es-truststore-jks --from-file=certs/es-cert.jks\n  ```\n\n* Modify the `app-deploy.yaml` to add environment variables and mount point.\n\n```yaml\n  env:\n    - name: KAFKA_BROKERS\n      valueFrom:\n        configMapKeyRef:\n          key: brokers\n          name: kafka-brokers\n    - name: KAFKA_APIKEY\n      valueFrom:\n        secretKeyRef:\n          key: binding\n          name: es-cp4i-apikey\n          optional: true\n    - name: CERT_LOCATION\n      value: /config/certs/truststore.jks\n```\n\n\nThe [Appsody Operator](https://appsody.dev/docs/reference/appsody-operator/) is a required prerequisite for deploying the microservice to a remote Kubernetes or OpenShift cluster. If the operator is not present in the current project, `appsody deploy... ` will add one.\n\nTo deploy the microservice to a remote cluster:\n\n```shell\n# Get the route to reach the docker private registry\noc get route --all-namespaces | grep registry\n# Define the path as environment variable\nexport IMAGE_REGISTRY=default-route-openshift-image-registry.gse-eda-demo-202005-fa9ee67c9ab6a7791435450358e564cc-0000.us-south.containers.appdomain.cloud\n# Deploy with appsody\n\nappsody deploy -t vaccine-cold-chain/vaccine-order-mgr:0.0.1 --push-url $IMAGE_REGISTRY --push --no-build --namespace vaccine-cold-chain\n```\n\n- You can omit the `--no-build` flag to have Appsody perform a build before deploying the application.\n- _**Note:**_ Performing a build at deploy time requires specifying the absolute container reference path, as well as the `--push` flag.\n- The neccesary deployment parameter information will be read from the `app-deploy.yaml` file in the same directory.\n\n## Usage Details\n\n### REST APIs\n\nThe REST end point for this service expose the following OpenAPI:\n\n ![4](./images/openapi.png)\n\n","type":"Mdx","contentDigest":"f5653db3884a26f4cd0ff663da9abc37","counter":209,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Vaccine Order Management","description":"This microservice manage order for vaccine"},"exports":{},"rawBody":"---\ntitle: Vaccine Order Management\ndescription: This microservice manage order for vaccine\n---\n<PageDescription>\nThis microservice manages vaccine order for a world wide demand and distribution.\n</PageDescription>\n\n<AnchorLinks>\n  <AnchorLink>Overview</AnchorLink>\n  <AnchorLink>Build with s2i</AnchorLink>\n  <AnchorLink>Run Locally</AnchorLink>\n  <AnchorLink>Deploy to OpenShift</AnchorLink>\n  <AnchorLink>Usage Details</AnchorLink>\n</AnchorLinks>\n\n## Overview\n\nThis project implements a very simple event driven microservice to support the Create, Read, Update, of vaccine orders. This implementation highlights the following capbilities / patterns:\n\n* Quarkus reactive microservice using Microprofile 3.x - reactive messaging extension \n* DB2 with Hibernate ORM with Quarkus Panache\n* Quarkus Debezium Outbox pattern to get OrderEvents table and change data capture with Debezium.\n\nIn term of business scenario, a sale representative uses his mobile device to enter information about a vaccine order to be shipped to a given countries or a province within a country. \n\n ![](./images/order-ui.png)\n\nThe user interface is for demonstration purpose but illustrate some standard Vuejs development practices. \n\n ![](./images/vaccine-order-1.png)\n\n\nThe component writes to the database (DB2) all the orders received, but also produce records to Kafka via the Outbox pattern and change data capture.\n\n**Github repository:** [Vaccine-order-mgr](https://github.com/ibm-cloud-architecture/vaccine-order-mgr)\n\n**Order Life Cycle**\n\nThe order follows a set of states as described in the following diagram:\n\n ![](./images/vaccine-order-2.png)\n\n**Kafka topics produced to:**\n\n\n**Events produced:**\n\nWe will simplify the process and aggregate in the following event types:\n\n* orderCreated\n* orderUpdated\n\nSome events are related to the vaccine lot\n\n* lotAssignedToOrder\n* lotLoaded\n* lotDelivered\n\n## Build with s2i\n\nThis microservice is built using maven and Quarkus extensions. We have already pushed the last version of this service on dockerhub, if you do not want to build it. \n\nTo build and run locally see the [repository main readme]() as we have different docker-compose file to run in demonstration mode or in development mode to add more features to existing code base.\n\nIn this section we address how to use OpenShift Source to Image to build and deploy the application to OpenShift. The application is using environment variables to access to user, password, URLs to access DB2, and Kafka. So first thing is to define such secrets.\n\nAs an example we use a OpenShift project called vaccine_solution created with a command like `oc new-project vaccine_solution`.\n\n### Pre requisites\n\nThe orders are persisted in an external DB2 instance running on IBM Cloud Pack for Data. You need to get the username and password to connect to the DB2 instance with the jdbc URL (something like jdbc:db2://dashdb-....:50001/BLUDB)\n\nGet an instance of Kafka deployed on OpenShift (Strimzi, [Event Streams](https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/overview/pre-requisites#install-event-streams-using-operators)...). For Event Streams get URL of the bootstrap server and the service credentials (TLS certificates) following [those instructions.](https://ibm-cloud-architecture.github.io/refarch-eda/use-cases/overview/pre-requisites#getting-tls-authentication-from-event-streams-on-openshift)\n\n### Defining secrets\n\nWe need to get IBM DB2 on Cloud credentials as secrets. So from the DB2 service credentials get the following attributes: user, password, and JDBC URL. You need to encrypt each of those values:\n\n```shell\n# Example of URL encryption\necho \"jdbc:db2://dashdb-txn-sbox-....services.dal.bluemix.net:50001/BLUDB:sslConnection=true;\" | base64\n```\n\nThen define a secret manifest with a command like:\n\n```shell\noc apply -f - <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: vaccine-order-db-secret\ndata:\n    db.url: ...encrypted URL...\n    db.user: ...encrypted user..\n    db.password: ...encrypted pwd\nEOF\n```\n\n\n```shell\n# if not logged yes to your openshift cluster where the docker private registry resides do:\noc login --token=... --server=https://c...\n\n# Then build the code using source 2 image and push the image to the internal registry\nmvn package -Dui.deps -Dui.dev -Dquarkus.kubernetes.deploy=true -DskipTests\n```\n\nIt can take some seconds to build and deploy: oc get pods -w lets you see the build pods and the running app once the build is done. As we expose the application an OpenShift route was created. The url is visible at the end of the build output, something like:\n\n...The deployed application can be accessed at: http://quarkus-kstreams-lab3...\n\n## Run\n\n\n### Deployment Parameters\n\nThe following deployment parameters are defined in the `app-deploy.yaml` file:\n\n| Name                                     | Required | Description                                                                                                            |\n|------------------------------------------|----------|------------------------------------------------------------------------------------------------------------------------|\n| KAFKA_BROKERS                            | YES      | Comma-separated list of Kafka brokers to connect to                                                                    |\n| KAFKA_APIKEY                             | NO       | API Key used to connect to SASL-secured Kafka brokers. This is required when connecting to IBM Event Streams clusters. |\n| TRUSTSTORE_ENABLED                       | NO       | Required to be set to `true` when connecting to IBM Event Streams on the IBM Cloud Pak for Integration (CP4I).         |\n| TRUSTSTORE_PATH                          | NO       | The local path to the required truststore file when connecting to IBM Event Streams on CP4I. See [**Volume Mounts**](#volume-mounts) below.  |\n| TRUSTSTORE_PWD                           | NO       | The password for the truststore file used for IBM Event Streams server verification. |\n| DBUSER | YES | Database user |\n| DBPWD | YES | Database user password |\n| SSLJDBCURL | YES | JDBC URL to connect to the database | \n\nYou can define a `.env` script to export the environment variables. \n\n### Run Locally\n\nWhen running the microservice locally you must specify all the required [deployment parameters](#deployment-parameters) environment variables. When using `appsody run` use the `--docker-options` flag being passed in from the Appsody CLI command. \nTwo options to start locally, one with quarkus, the other one with appsody\n\n**With Quarkus:**\n\n```shell\nsource ./scripts/setenv.sh\n./mvnw quarkus:dev\n```\n\n**With Appsody:** \n\n```shell\nsource ./scripts/setenv.sh\n\nappsody run --docker-options \"-e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY -e DBPWD=$DBPWD -e DBUSER=$DBUSER -e SSLJDBCURL=$SSLJDBCURL  -v $(pwd)/certs/es-cert.jks:/deployments/certs/es-cert.jks\"\n```\n\nFor more details on running the microservice locally, consult the Appsody run documentation as well as the deployment information contained in the app-deploy.yaml file.\n\n### Volume mounts\n\nThe order manager microservice requires up to one file to be injected at runtime for proper operation. As noted in the `TRUSTSTORE_PATH` parameter above, these files are SSL-based certificates which are required to verify the identity of the external service when calling it. These files are provided as `--docker-options \"-v host-src:container-dest ...\"` when running the microservice locally and as a Volume Mount when running the microservice on a Kubernetes cluster.\n\nThe `TRUSTSTORE_PATH` parameter is documented in the **Event Streams Certificates** section of the [Prerequisites](/microservices/prereqs/#ibm-event-streams-on-redhat-openshift-container-platform) page. The Appsody run command should include a parameter similar to `-v ./certs/es-cert.jks:/config/resources/security/es-cert.jks` in its `--docker-options` string to run this microservice locally.\n\n**Example:** `appsody run --docker-options \"-v /Users/myuser/Downloads/es-cert.jks:/config/resources/security/es-ssl/es-cert.jks\" ...`\n\n## Deploy to Openshift \n\n* Define a config map for the kafka brokers URL coming from the Event streams cluster connection panel:\n\n ![3](./images/es-cluster-connect.png)\n\n  ```shell\n  oc create configmap kafka-brokers --from-literal=brokers='es-cp4i-ibm-es-proxy-route-bootstrap-eventstreams-cp4i.gse-eda-demo-202005-fa9ee67c9ab6a7791435450358e564cc-0000.us-south.containers.appdomain.cloud:443' -n vaccine-cold-chain\n\n  ```\n\n* Define a secret for the event streams API key\n\n  ```shell\n  oc create secret generic es-cp4i-apikey --from-literal=binding='b77......tgMJZ' -n vaccine_solution\n  ```\n\n* Add a secret for the java truststore, downloaded from Event Stream console or using the CLI `cloudctl es certificates --format jks`\n\n  ```shell\n  oc create secret generic es-truststore-jks --from-file=certs/es-cert.jks\n  ```\n\n* Modify the `app-deploy.yaml` to add environment variables and mount point.\n\n```yaml\n  env:\n    - name: KAFKA_BROKERS\n      valueFrom:\n        configMapKeyRef:\n          key: brokers\n          name: kafka-brokers\n    - name: KAFKA_APIKEY\n      valueFrom:\n        secretKeyRef:\n          key: binding\n          name: es-cp4i-apikey\n          optional: true\n    - name: CERT_LOCATION\n      value: /config/certs/truststore.jks\n```\n\n\nThe [Appsody Operator](https://appsody.dev/docs/reference/appsody-operator/) is a required prerequisite for deploying the microservice to a remote Kubernetes or OpenShift cluster. If the operator is not present in the current project, `appsody deploy... ` will add one.\n\nTo deploy the microservice to a remote cluster:\n\n```shell\n# Get the route to reach the docker private registry\noc get route --all-namespaces | grep registry\n# Define the path as environment variable\nexport IMAGE_REGISTRY=default-route-openshift-image-registry.gse-eda-demo-202005-fa9ee67c9ab6a7791435450358e564cc-0000.us-south.containers.appdomain.cloud\n# Deploy with appsody\n\nappsody deploy -t vaccine-cold-chain/vaccine-order-mgr:0.0.1 --push-url $IMAGE_REGISTRY --push --no-build --namespace vaccine-cold-chain\n```\n\n- You can omit the `--no-build` flag to have Appsody perform a build before deploying the application.\n- _**Note:**_ Performing a build at deploy time requires specifying the absolute container reference path, as well as the `--push` flag.\n- The neccesary deployment parameter information will be read from the `app-deploy.yaml` file in the same directory.\n\n## Usage Details\n\n### REST APIs\n\nThe REST end point for this service expose the following OpenAPI:\n\n ![4](./images/openapi.png)\n\n","fileAbsolutePath":"/Users/jeromeboyer/Code/AllCloudPaks/vaccine-solution-main/docs/src/pages/solution/orderms/index.mdx"}}}}