{"componentChunkName":"component---src-pages-index-mdx","path":"/","result":{"pageContext":{"frontmatter":{"title":"Vaccine Delivery at Scale","description":"An innovative vaccine delivery supply chain solution"},"relativePagePath":"/index.mdx","titleType":"append","MdxNode":{"id":"0180821f-cff2-5832-9aad-4f700cb277e5","children":[],"parent":"39fa7886-f71f-5664-85bd-8641bcb21a13","internal":{"content":"---\ntitle: Vaccine Delivery at Scale\ndescription: An innovative vaccine delivery supply chain solution\n---\n\nInspired by J&J’s Road to Vaccine, [![0](./images/road-to-vaccine.png)](https://www.youtube.com/watch?v=koac13B-DvM) that educated the world through its leadership in science and innovation, we invite you on an experiential Vaccine’s Journey with IBM through the lens of technology and open innovations.\n\n## Business scenario\n\nAs the world awaits the release of the COVID-19 vaccines; we’ve learnt four things about the vaccines themselves:\n\n1.\tThe vaccine once manufactured needs to be in a stable cold state up until inoculation\n2.\tThe vaccine travels through various sites across the globe from manufacturing sites to remote clinical trial sites to actual distribution sites to citizens\n3.\tThe vaccines when ready for release will rise to be the #1 counterfeit product in the world\n4.\tThere will be a need for Billions of vaccine, so the vaccines will be manufactured in multiple locations \n\n\nExiting the clinical trial phase; the challenge ahead for vaccine manufacturers along with their manufacturing partners lies in effectively delivering the billion vaccines to the most needed areas of the world under uncertain conditions, constrained supplies for vaccine vials, refrigerator container for transportation and fragmented supply chains. \n\n ![2](./images/biz-arch.png)\n\n## Executive Overview\n\nThe industry is coming together as an open source project under the Linux foundation to ensure that the authenticity of the vaccine is maintained, and a platform is created that is compliant with the industry and is approved by the FDA. The IBM implementation demo of the platform as shown in the diagram above leverages open hybrid cloud capabilities using IBM Red Hat Openshift on a pharmaceutical industry compliant cloud provider. The platform leverages IBM Cloud Paks and brings together advanced analytics and AI capabilities coupled with events processing to rapidly build and deploy cognitive solutions and intelligent workflows for vaccine distribution optimization, faulty container management and detetction, vaccine program success, order management and fraud and crime prevention for getting the vaccines safely in the hands of the doctors and ensuring the authenticity of the vaccine through block chain and removal of bad batch of vaccines through machine learning models and block chain verification.  IBM’s cloud pak are built on top of IBM Red Hat Open Shift.\n\nIn this demo solution we use: \n\n1. IBM’s cloud pak for application which allows you to build, deploy and run applications and reduces development time by up to 84%. \n1. IBM’s cloud pak for data allows you to collect, organize, analyze data and infuse insights in processes. It reduces the time to get the data ready for AI to days. \n1. IBM’s cloud pak for integration allows you to integrate apps, data , cloud services and APIs and eliminates integration cost by up to 33%\n1. IBM’s cloud pak for automation transforms business processes, decisions and content and reduces manual processes up to 80%\n1. IBM’s cloud pak for multicloud management provides multicloud visibility, governance and automation and reduces the IPop expense by up to 75%\n\nVariability in events both internally through the business processes and external events impacting the supply chain across multiple business entities coupled with data residing in multiple clouds presents challenges around anomaly detection that ultimately the vaccin developer is responsible to decision and act on by modifying business processes.\n\nA traditional architecture requires creating new interfaces, integration into systems,  federation and organization of data into a data lake to be ready for any derivation of insights.\n\nOur demonstration today, showcases a developer ready modern architecture comprising of integrated middleware that are used as building blocks to deliver the end to end solution. Use of DevOps tooling and practices accelerates the solution by three factor.\n\n## What we cover\n\n* Speed to innovate and shorten time to deploy to production\ndesign thinking, even storming, microservices, small team, devops, MLops...\n* Focus end to end solution running in container on Openshift platform on any cloud provider.\n* Using blockchain as multiple business partners are involved, we need to have trusted in data, single source of truth to keep records about the manufactured vaccine lots.\n* How to monitor cold chain for refrigerated vaccine during the packaging and transportation using IoT, events, reactive microservices, rules, predictive scoring and blockchain.\n* How to develop the solution using Java based microprofile apps, with CI/CD practices using Openshift and kubernetes tooling.\n* Scale the solution locally but also at the worldwide level using multi cloud management.\n\n## The IFMA process\n\nThe high level vaccine manufacturing process is presented in the figure below.\n\n![1](./images/ifma-process.png)\n\nThe important points we want to consider in this Minimum Viable Solution are:\n\n* Multiple partners are engaged in this process.\n* Intermediate steps of manufacturing the vaccine used transportation between manufacturers in same or different countries.\n* We want to consider the vaccine lot to be released and transported to target destination via airplane.\n* We assume the lots are within refrigerated containers.\n\n## Solution development process\n\nIBM research, MIT Data Science Lab and pharmaceutical companies use machine learning models to identify potential hotspots with granular location precision for making informed the supply chain decisions. This requires trust and transparency in AI before triggering any changes to their supply chain execution. \n\nThe diagram below is a minimum viable product solution design\n\n ![3](./design/images/vaccine-comp-view.png)\n\nWe will now highlight features and functions of the solution:\n\nAs shown in the component view above, a potential hotspot is detected in Miami, this triggers the creation of orders in the Vaccine Order Portal. The vaccine order stipulates the amount of vaccines to be delivered to any place in the world, with varying level of criticality and delivery timeframe. This triggers the [Order and Reefer optimization](./design/voro/) service that invokes a series of complex optimization planning:\n\n* To optimize the most cost effective vaccine sourcing and shipping routes to meet the demand subjected to the availability of both vaccines and refrigerator containers. \n* To optimize the flow of vaccine refrigerator containers including repositioning of the empty containers to support the optimal fulfillment plans\n \nFurthermore, given the dynamic nature of the situation, the plans need to be continuously optimized with the latest information. \n\nA vaccine typically travels through multiple sites before being ready for shipment. Multiple companies are involved to manufacture the vaccines. Vaccines need to be handled at an optimal cool temperature (36-46 degrees F) and managed through the cold chain process. For high-value items like vaccines, clinical trial samples and lifesaving medications,  a fluctuation as minor as 2 degrees Celsius can reduce or even eliminate effectiveness, the stakes couldn't be higher. \n\nAs the shipment of vaccines is underway, cold chain monitoring service monitors the performance of the cold chain in real time. This is supported by two components: \n\n* a real time stateful operator connected to the event streams coming as reefer telemetries: The refrigerated containers, those would be used to ship the Vaccines to the Medical facilities, need monitoring. That is to ensure that all sensors within the containers are working properly so that its internal control system maintains  the necessary temperature and the concentration of cryogenic fluids. Otherwise the Vaccines would be spoiled and cannot be used for the treatment of patients. The data of various sensors from the containers (while they are on job to fulfill a shipment) can be continuously captured as [event data and kept in any kind of datastore](./solution/cold-monitoring/). \n* an anomaly detection scoring model developed, deployed and monitored using Watson capabilities within [Cloud Pak for Data](./solution/cp4d/). Like any other Cloud Pak, Cloud Pak for Data can also run in any Cloud infrastructure - IBM Cloud, Azure, Google or Amazon or even in On Premise infrastructure.\n\nThe telemetry can be used to build a AI model to continuously check if any irregularity happening in the Containers while in move (which can in turn spoil the Vaccines).\n\nOnce we have detected the anomaly, a process is triggered in conjunction with blockchain Ledger to remove the bad batch of vaccines from the supply chain. The maintenance business process uses IBM cloud pak for automation. \n\nThe blockchain component is key, in this solution, to ensure continuous transparency between the different business partners involved in this end to end manufacturing and delivery of the vaccine lots.  By this time many counterfeit vaccines exist in the market. The physician at the point of inoculation uses IBM’s Research led innovation - IBM’s Crypto Anchor Verifier. After scanning the vaccine, the Verifier records its unique wavelength and microscopic details on the blockchain; verifying its authenticity against the original digital fingerprint captured at source; all in a matter of sub seconds.\n\n### How to start this innovative journey\n\n#### Problem\n\nThe IT solution needs to be operational within three months.\n\n#### Analysis and design modern approach \n\nWhen developing innovative solution we are using the [IBM Garage Methodology](https://www.ibm.com/garage/method) to better understand the requirements, push for innovation and lean solution. We have applied this method to deevelop the current Minimum Viable Product for this solution. You can follow the steps as below:\n\nFrom the IFMA process introduced in previous section, we can work with the subject matter experts to understand the vaccine manufacturing process using [design thinking and event storming workshops](./design/dtw/) so we can understand events, domain and subdomains. \n\nAs part of the lean startup approach, we do not want to spend months discussing on architecture and development practices, we want to establish a minimum viable architecture, that can evolve over time and during the implementation to adapt to new user stories or pivot.\nSo too model the solution and its components, architects and lead developers apply a [Domain Driven Design](design/ddd/) approach to discover bounded context and future microservice landscape. From there they can build the traditional [system context view](/design/syst-ctx/) and [component view](/design/comp-view/) necessary to present a minimum viable architecture.\n\n### Start the development \n\n#### Problem\n\nIs it possible to start as early as the design thinking and architecture workshops are done?\n\n#### The how \n\nThis is where are methodology includes the iteration 0, and this is where Cloud Pak for Application helps dramatically to get code template, git repositories and devops pipeline ready.\n\nConcretly from the decomposition in components, we can jump start the development using [Solution Designer](design/cp4a-sol-builder/) and [Appsody](https://appsody.dev/) Java microprofile stacks ([OpenLiberty](https://openliberty.io/) or [Quarkus](https://quarkus.io/)), combined with the CI/CD capabilities of [gitops](https://www.weave.works/technologies/gitops/) and [Tekton](https://github.com/tektoncd). \n\n### Event driven microservice best practices\n\n#### Problem\n\nThe solution established during the architecture workshop, involves different business partners, different systems, and is asynchronous and event based. So what will be the best approach to develop those new components as microservices.\n\n#### The how\n\nThe asynchronous nature of the process and the need for loosely coupled integration between services,  we are mixing API calls and event driven solution. We will use some of the event driven patterns like [event sourcing](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/), [Command Query Responsability Seggregation](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/cqrs/), [Saga](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) and applying [real time analytics](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/realtime-analytics/) on the IoT device metrics.  Modern cloud native architecture uses event backbone for microservice communication, and [Apache Kafka]()https://kafka.apche.org) is one of the main technology of choice. [IBM Event Streams](https://www.ibm.com/cloud/event-streams) as part of the [Cloud Pak for Integration](https://www.ibm.com/cloud/cloud-pak-for-integration) deliver an enhanced supported version of Kafka. We are [detailing how the components](/solution/environment/#integration)of the solution work together using event driven reactive messaging approach. \n\n### Supply chain challenge\n\nThe vaccine order stipulates the amount of vaccines to be delivered to any place in the world, with varying level of criticality and delivery timeframe. This invokes a series of complex optimization planning:\n\n* To optimize the vaccine sourcing and shipping routes, most cost effective to meet the demand subjected to the availability of both vaccines and refrigerator containers.\n* To optimize the flow of vaccine refrigerator containers including repositioning the empty containers to support the optimal fulfillment plans\n \nFurthermore, given the dynamic nature of the situation, the plans need to be continuous optimized with the latest information.\n\n#### The how\n\nGiven the limited number of vaccine refrigerator containers available in the supply chain, and limited available lots at manufacturing sites or warehouses, the [Vaccine Order & Reefer Optimizer](design/voro/) seeks to create an optimized fulfillment plan for each vaccine order in real time and continue to improve or repair the delivery plans as new information become available. \n\nThe application deployed on OpenShift lives as a side by side extension to ERP allowing independent updates separate from the core supply chain system and keeping the core clean.\n\nThis service is combined is the order management system. As part of a very simple solution we have implemented a Java Quarkus based [order management service](/solution/orderms/) to expose REST APIs to be able to demonstrate the solution end to end. \n\n### Monitor the cold chain. \n\nOnce vaccine is manufactured its digital fingerprint is tracked through shipping to delivery transparently via blockchain. The solution involves monitoring the temperature of the refrigerated containers through cold-chain monitoring. A model to detect the anomaly in the temperatures identifies the faulty containers crossing temperature thresholds which triggers a process to remove the faulty containers from the shipment and informing the supply chain.\n\n\n#### The how\n\nThe solution includes a Kafka Stream and reactive messaging component that gets telemetry data every 5 minutes for each of the refrigerator containers, and applies stateful logic with time windows.  The component is described in this  [Kafka Streams application section](/solution/cold-monitoring/). This cold chain monitoring agent is enhanced to call a predictive scoring service to detect reefer container anomaly from the same telemetries.\n\n### Anomaly detection model \n\nAs we do anomaly detection with a machine learned model, we need to develop the model and manage the data about the product, the telemetries,...\n\n#### The how \n\nThe predictive scoring service to detect reefer container anomaly is developed using a [machine learning approach using Watson Studio](/analyze/ws-ml-dev) and Data governance capabilities from the [Cloud Pak for Data](https://www.ibm.com/products/cloud-pak-for-data).\n\n### End to end traceability and trustability\n\nTraceability is key to avoid fraud, and ensure quality of the end to end delivery. As the vaccine vials travel by air and then shipping companies with last mile contactless delivery enabled via drones; the blockchain ledger is used to ensure continuous transparency.  By this time many counterfeit vaccines exist in the market. The physician at the point of inoculation uses IBM’s Research led innovation - IBM’s Crypto Anchor Verifier. After scanning the vaccine, the Verifier records its unique wavelength and microscopic details on the blockchain; verifying its authenticity against the original digital fingerprint captured at source; all in a matter of sub seconds.\n\nThe vaccine developer, the heathcare agency in the importing country, the physician inoculating the vaccine and the citizen receiving the vaccine are all rest assured on the authenticity of the vaccine and the vaccine developer moves to solve bigger problems through science and innovation.\n\n#### The how \n\nSo the core solution needs to adopt [Blockchain hyperledger](https://www.ibm.com/blockchain) to track the life cycle of the vaccine lots: lot manufacturing events, cold chain violation events, and shipment events are logged into the hyperledger.\n\n### Fix reefer anomaly\n\nTo make the anomaly detection actionable, we can integrate a [human centric business process](https://www.ibm.com/cloud/cloud-pak-for-automation) to support the [refrigerator container maintenance](/solution/bpm/), triggered from the AI scoring service, to avoid bigger and costly failure and optimize the maintenance cost.\n\n\n### Multi cloud providers\n\nWhile the vaccine development companies uses one cloud provider, its business partners may use different one, like IBM Cloud as the preferred cloud provider for their technology stack have independent security stacks with limited flexibility to engineer the solution to a common cloud provider API. \n\n#### The how\n\nPowered by OpenShift the solution was built once and deployed anywhere. Policy driven orchestration ensures resiliency given the ephemeral nature of cloud. The solution and the dependent products used needs to be easily deployed to different cloud providers. [Multi Cloud management](/mcm/problem/) provides visibility and governance control across multi-cloud targets. J&J ultimately has the gov contracts and needs to deliver on the promise\n\n### Cybersecurity to ensure integrity and safety\n\nThe solution is secured across multi-cloud targets federating queries across the varied SIEM data sources.\n\n\n## Final Warming\n\n<InlineNotification kind=\"warning\">The implemented code does not represent any best practices in term of software development and production delivery. Consider to be a \"hello world ++\" for most of the components. Those components are exposing basic REST end points and a simple data model to support the main concepts of the business problem with adhoc persistence layer.</InlineNotification>\n","type":"Mdx","contentDigest":"8a44f455d8259caff81a46a665f5095c","counter":191,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Vaccine Delivery at Scale","description":"An innovative vaccine delivery supply chain solution"},"exports":{},"rawBody":"---\ntitle: Vaccine Delivery at Scale\ndescription: An innovative vaccine delivery supply chain solution\n---\n\nInspired by J&J’s Road to Vaccine, [![0](./images/road-to-vaccine.png)](https://www.youtube.com/watch?v=koac13B-DvM) that educated the world through its leadership in science and innovation, we invite you on an experiential Vaccine’s Journey with IBM through the lens of technology and open innovations.\n\n## Business scenario\n\nAs the world awaits the release of the COVID-19 vaccines; we’ve learnt four things about the vaccines themselves:\n\n1.\tThe vaccine once manufactured needs to be in a stable cold state up until inoculation\n2.\tThe vaccine travels through various sites across the globe from manufacturing sites to remote clinical trial sites to actual distribution sites to citizens\n3.\tThe vaccines when ready for release will rise to be the #1 counterfeit product in the world\n4.\tThere will be a need for Billions of vaccine, so the vaccines will be manufactured in multiple locations \n\n\nExiting the clinical trial phase; the challenge ahead for vaccine manufacturers along with their manufacturing partners lies in effectively delivering the billion vaccines to the most needed areas of the world under uncertain conditions, constrained supplies for vaccine vials, refrigerator container for transportation and fragmented supply chains. \n\n ![2](./images/biz-arch.png)\n\n## Executive Overview\n\nThe industry is coming together as an open source project under the Linux foundation to ensure that the authenticity of the vaccine is maintained, and a platform is created that is compliant with the industry and is approved by the FDA. The IBM implementation demo of the platform as shown in the diagram above leverages open hybrid cloud capabilities using IBM Red Hat Openshift on a pharmaceutical industry compliant cloud provider. The platform leverages IBM Cloud Paks and brings together advanced analytics and AI capabilities coupled with events processing to rapidly build and deploy cognitive solutions and intelligent workflows for vaccine distribution optimization, faulty container management and detetction, vaccine program success, order management and fraud and crime prevention for getting the vaccines safely in the hands of the doctors and ensuring the authenticity of the vaccine through block chain and removal of bad batch of vaccines through machine learning models and block chain verification.  IBM’s cloud pak are built on top of IBM Red Hat Open Shift.\n\nIn this demo solution we use: \n\n1. IBM’s cloud pak for application which allows you to build, deploy and run applications and reduces development time by up to 84%. \n1. IBM’s cloud pak for data allows you to collect, organize, analyze data and infuse insights in processes. It reduces the time to get the data ready for AI to days. \n1. IBM’s cloud pak for integration allows you to integrate apps, data , cloud services and APIs and eliminates integration cost by up to 33%\n1. IBM’s cloud pak for automation transforms business processes, decisions and content and reduces manual processes up to 80%\n1. IBM’s cloud pak for multicloud management provides multicloud visibility, governance and automation and reduces the IPop expense by up to 75%\n\nVariability in events both internally through the business processes and external events impacting the supply chain across multiple business entities coupled with data residing in multiple clouds presents challenges around anomaly detection that ultimately the vaccin developer is responsible to decision and act on by modifying business processes.\n\nA traditional architecture requires creating new interfaces, integration into systems,  federation and organization of data into a data lake to be ready for any derivation of insights.\n\nOur demonstration today, showcases a developer ready modern architecture comprising of integrated middleware that are used as building blocks to deliver the end to end solution. Use of DevOps tooling and practices accelerates the solution by three factor.\n\n## What we cover\n\n* Speed to innovate and shorten time to deploy to production\ndesign thinking, even storming, microservices, small team, devops, MLops...\n* Focus end to end solution running in container on Openshift platform on any cloud provider.\n* Using blockchain as multiple business partners are involved, we need to have trusted in data, single source of truth to keep records about the manufactured vaccine lots.\n* How to monitor cold chain for refrigerated vaccine during the packaging and transportation using IoT, events, reactive microservices, rules, predictive scoring and blockchain.\n* How to develop the solution using Java based microprofile apps, with CI/CD practices using Openshift and kubernetes tooling.\n* Scale the solution locally but also at the worldwide level using multi cloud management.\n\n## The IFMA process\n\nThe high level vaccine manufacturing process is presented in the figure below.\n\n![1](./images/ifma-process.png)\n\nThe important points we want to consider in this Minimum Viable Solution are:\n\n* Multiple partners are engaged in this process.\n* Intermediate steps of manufacturing the vaccine used transportation between manufacturers in same or different countries.\n* We want to consider the vaccine lot to be released and transported to target destination via airplane.\n* We assume the lots are within refrigerated containers.\n\n## Solution development process\n\nIBM research, MIT Data Science Lab and pharmaceutical companies use machine learning models to identify potential hotspots with granular location precision for making informed the supply chain decisions. This requires trust and transparency in AI before triggering any changes to their supply chain execution. \n\nThe diagram below is a minimum viable product solution design\n\n ![3](./design/images/vaccine-comp-view.png)\n\nWe will now highlight features and functions of the solution:\n\nAs shown in the component view above, a potential hotspot is detected in Miami, this triggers the creation of orders in the Vaccine Order Portal. The vaccine order stipulates the amount of vaccines to be delivered to any place in the world, with varying level of criticality and delivery timeframe. This triggers the [Order and Reefer optimization](./design/voro/) service that invokes a series of complex optimization planning:\n\n* To optimize the most cost effective vaccine sourcing and shipping routes to meet the demand subjected to the availability of both vaccines and refrigerator containers. \n* To optimize the flow of vaccine refrigerator containers including repositioning of the empty containers to support the optimal fulfillment plans\n \nFurthermore, given the dynamic nature of the situation, the plans need to be continuously optimized with the latest information. \n\nA vaccine typically travels through multiple sites before being ready for shipment. Multiple companies are involved to manufacture the vaccines. Vaccines need to be handled at an optimal cool temperature (36-46 degrees F) and managed through the cold chain process. For high-value items like vaccines, clinical trial samples and lifesaving medications,  a fluctuation as minor as 2 degrees Celsius can reduce or even eliminate effectiveness, the stakes couldn't be higher. \n\nAs the shipment of vaccines is underway, cold chain monitoring service monitors the performance of the cold chain in real time. This is supported by two components: \n\n* a real time stateful operator connected to the event streams coming as reefer telemetries: The refrigerated containers, those would be used to ship the Vaccines to the Medical facilities, need monitoring. That is to ensure that all sensors within the containers are working properly so that its internal control system maintains  the necessary temperature and the concentration of cryogenic fluids. Otherwise the Vaccines would be spoiled and cannot be used for the treatment of patients. The data of various sensors from the containers (while they are on job to fulfill a shipment) can be continuously captured as [event data and kept in any kind of datastore](./solution/cold-monitoring/). \n* an anomaly detection scoring model developed, deployed and monitored using Watson capabilities within [Cloud Pak for Data](./solution/cp4d/). Like any other Cloud Pak, Cloud Pak for Data can also run in any Cloud infrastructure - IBM Cloud, Azure, Google or Amazon or even in On Premise infrastructure.\n\nThe telemetry can be used to build a AI model to continuously check if any irregularity happening in the Containers while in move (which can in turn spoil the Vaccines).\n\nOnce we have detected the anomaly, a process is triggered in conjunction with blockchain Ledger to remove the bad batch of vaccines from the supply chain. The maintenance business process uses IBM cloud pak for automation. \n\nThe blockchain component is key, in this solution, to ensure continuous transparency between the different business partners involved in this end to end manufacturing and delivery of the vaccine lots.  By this time many counterfeit vaccines exist in the market. The physician at the point of inoculation uses IBM’s Research led innovation - IBM’s Crypto Anchor Verifier. After scanning the vaccine, the Verifier records its unique wavelength and microscopic details on the blockchain; verifying its authenticity against the original digital fingerprint captured at source; all in a matter of sub seconds.\n\n### How to start this innovative journey\n\n#### Problem\n\nThe IT solution needs to be operational within three months.\n\n#### Analysis and design modern approach \n\nWhen developing innovative solution we are using the [IBM Garage Methodology](https://www.ibm.com/garage/method) to better understand the requirements, push for innovation and lean solution. We have applied this method to deevelop the current Minimum Viable Product for this solution. You can follow the steps as below:\n\nFrom the IFMA process introduced in previous section, we can work with the subject matter experts to understand the vaccine manufacturing process using [design thinking and event storming workshops](./design/dtw/) so we can understand events, domain and subdomains. \n\nAs part of the lean startup approach, we do not want to spend months discussing on architecture and development practices, we want to establish a minimum viable architecture, that can evolve over time and during the implementation to adapt to new user stories or pivot.\nSo too model the solution and its components, architects and lead developers apply a [Domain Driven Design](design/ddd/) approach to discover bounded context and future microservice landscape. From there they can build the traditional [system context view](/design/syst-ctx/) and [component view](/design/comp-view/) necessary to present a minimum viable architecture.\n\n### Start the development \n\n#### Problem\n\nIs it possible to start as early as the design thinking and architecture workshops are done?\n\n#### The how \n\nThis is where are methodology includes the iteration 0, and this is where Cloud Pak for Application helps dramatically to get code template, git repositories and devops pipeline ready.\n\nConcretly from the decomposition in components, we can jump start the development using [Solution Designer](design/cp4a-sol-builder/) and [Appsody](https://appsody.dev/) Java microprofile stacks ([OpenLiberty](https://openliberty.io/) or [Quarkus](https://quarkus.io/)), combined with the CI/CD capabilities of [gitops](https://www.weave.works/technologies/gitops/) and [Tekton](https://github.com/tektoncd). \n\n### Event driven microservice best practices\n\n#### Problem\n\nThe solution established during the architecture workshop, involves different business partners, different systems, and is asynchronous and event based. So what will be the best approach to develop those new components as microservices.\n\n#### The how\n\nThe asynchronous nature of the process and the need for loosely coupled integration between services,  we are mixing API calls and event driven solution. We will use some of the event driven patterns like [event sourcing](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/event-sourcing/), [Command Query Responsability Seggregation](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/cqrs/), [Saga](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/saga/) and applying [real time analytics](https://ibm-cloud-architecture.github.io/refarch-eda/patterns/realtime-analytics/) on the IoT device metrics.  Modern cloud native architecture uses event backbone for microservice communication, and [Apache Kafka]()https://kafka.apche.org) is one of the main technology of choice. [IBM Event Streams](https://www.ibm.com/cloud/event-streams) as part of the [Cloud Pak for Integration](https://www.ibm.com/cloud/cloud-pak-for-integration) deliver an enhanced supported version of Kafka. We are [detailing how the components](/solution/environment/#integration)of the solution work together using event driven reactive messaging approach. \n\n### Supply chain challenge\n\nThe vaccine order stipulates the amount of vaccines to be delivered to any place in the world, with varying level of criticality and delivery timeframe. This invokes a series of complex optimization planning:\n\n* To optimize the vaccine sourcing and shipping routes, most cost effective to meet the demand subjected to the availability of both vaccines and refrigerator containers.\n* To optimize the flow of vaccine refrigerator containers including repositioning the empty containers to support the optimal fulfillment plans\n \nFurthermore, given the dynamic nature of the situation, the plans need to be continuous optimized with the latest information.\n\n#### The how\n\nGiven the limited number of vaccine refrigerator containers available in the supply chain, and limited available lots at manufacturing sites or warehouses, the [Vaccine Order & Reefer Optimizer](design/voro/) seeks to create an optimized fulfillment plan for each vaccine order in real time and continue to improve or repair the delivery plans as new information become available. \n\nThe application deployed on OpenShift lives as a side by side extension to ERP allowing independent updates separate from the core supply chain system and keeping the core clean.\n\nThis service is combined is the order management system. As part of a very simple solution we have implemented a Java Quarkus based [order management service](/solution/orderms/) to expose REST APIs to be able to demonstrate the solution end to end. \n\n### Monitor the cold chain. \n\nOnce vaccine is manufactured its digital fingerprint is tracked through shipping to delivery transparently via blockchain. The solution involves monitoring the temperature of the refrigerated containers through cold-chain monitoring. A model to detect the anomaly in the temperatures identifies the faulty containers crossing temperature thresholds which triggers a process to remove the faulty containers from the shipment and informing the supply chain.\n\n\n#### The how\n\nThe solution includes a Kafka Stream and reactive messaging component that gets telemetry data every 5 minutes for each of the refrigerator containers, and applies stateful logic with time windows.  The component is described in this  [Kafka Streams application section](/solution/cold-monitoring/). This cold chain monitoring agent is enhanced to call a predictive scoring service to detect reefer container anomaly from the same telemetries.\n\n### Anomaly detection model \n\nAs we do anomaly detection with a machine learned model, we need to develop the model and manage the data about the product, the telemetries,...\n\n#### The how \n\nThe predictive scoring service to detect reefer container anomaly is developed using a [machine learning approach using Watson Studio](/analyze/ws-ml-dev) and Data governance capabilities from the [Cloud Pak for Data](https://www.ibm.com/products/cloud-pak-for-data).\n\n### End to end traceability and trustability\n\nTraceability is key to avoid fraud, and ensure quality of the end to end delivery. As the vaccine vials travel by air and then shipping companies with last mile contactless delivery enabled via drones; the blockchain ledger is used to ensure continuous transparency.  By this time many counterfeit vaccines exist in the market. The physician at the point of inoculation uses IBM’s Research led innovation - IBM’s Crypto Anchor Verifier. After scanning the vaccine, the Verifier records its unique wavelength and microscopic details on the blockchain; verifying its authenticity against the original digital fingerprint captured at source; all in a matter of sub seconds.\n\nThe vaccine developer, the heathcare agency in the importing country, the physician inoculating the vaccine and the citizen receiving the vaccine are all rest assured on the authenticity of the vaccine and the vaccine developer moves to solve bigger problems through science and innovation.\n\n#### The how \n\nSo the core solution needs to adopt [Blockchain hyperledger](https://www.ibm.com/blockchain) to track the life cycle of the vaccine lots: lot manufacturing events, cold chain violation events, and shipment events are logged into the hyperledger.\n\n### Fix reefer anomaly\n\nTo make the anomaly detection actionable, we can integrate a [human centric business process](https://www.ibm.com/cloud/cloud-pak-for-automation) to support the [refrigerator container maintenance](/solution/bpm/), triggered from the AI scoring service, to avoid bigger and costly failure and optimize the maintenance cost.\n\n\n### Multi cloud providers\n\nWhile the vaccine development companies uses one cloud provider, its business partners may use different one, like IBM Cloud as the preferred cloud provider for their technology stack have independent security stacks with limited flexibility to engineer the solution to a common cloud provider API. \n\n#### The how\n\nPowered by OpenShift the solution was built once and deployed anywhere. Policy driven orchestration ensures resiliency given the ephemeral nature of cloud. The solution and the dependent products used needs to be easily deployed to different cloud providers. [Multi Cloud management](/mcm/problem/) provides visibility and governance control across multi-cloud targets. J&J ultimately has the gov contracts and needs to deliver on the promise\n\n### Cybersecurity to ensure integrity and safety\n\nThe solution is secured across multi-cloud targets federating queries across the varied SIEM data sources.\n\n\n## Final Warming\n\n<InlineNotification kind=\"warning\">The implemented code does not represent any best practices in term of software development and production delivery. Consider to be a \"hello world ++\" for most of the components. Those components are exposing basic REST end points and a simple data model to support the main concepts of the business problem with adhoc persistence layer.</InlineNotification>\n","fileAbsolutePath":"/home/runner/work/vaccine-solution-main/vaccine-solution-main/docs/src/pages/index.mdx"}}}}